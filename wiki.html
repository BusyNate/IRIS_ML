<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Drowsiness Detection Project Wiki</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <!-- Chosen Palette: Warm Neutrals -->
    <!-- Application Structure Plan: The SPA is designed as a single-page wiki. It features a prominent Table of Contents (TOC) at the top for quick navigation to distinct thematic sections: Project Tools Overview, Data Preparation, Model Configuration, Model Tuning, and Local Deployment. This structure facilitates comprehensive information consumption and exploration, allowing users to delve into specific workflow stages or review the entire process sequentially. The wiki format prioritizes clarity and direct access to information, making it an effective educational and reference tool. -->
    <!-- Visualization & Content Choices:
        - Project Tools Overview: Goal -> Inform -> Table -> HTML/CSS -> To provide a quick, categorized summary of the main tools.
        - Data Preparation: Goal -> Inform/Organize -> Detailed text, code blocks, interactive pipeline flowchart -> HTML/CSS/JS -> To explain the sequential steps of data processing and allow interactive exploration of each sub-step.
        - Model Configuration: Goal -> Inform -> Detailed text, code blocks -> HTML/CSS -> To explain the model architecture and compilation process.
        - Model Tuning: Goal -> Inform/Compare/Engage -> Detailed text, code blocks, interactive bar chart (Chart.js) -> To explain tuning parameters and their impact on model performance, making abstract concepts tangible through simulation.
        - Local Deployment: Goal -> Inform/Engage -> Detailed text, code blocks, interactive prototype simulation -> HTML/CSS/JS -> To demonstrate the final application's functionality and user interaction.
        - CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #F0F8FF; /* Changed to blueish white (AliceBlue) */
            color: #4A4A4A;
        }
        .nav-link {
            color: #71717A;
            transition: color 0.2s;
        }
        .nav-link:hover {
            color: #D97706;
        }
        .content-section {
            padding-top: 2rem;
            padding-bottom: 2rem;
            /* display: none; Removed display:none for non-paginated view */
        }
        /* .content-section.active { display: block; } Removed active class for non-paginated view */
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 600px;
            margin-left: auto;
            margin-right: auto;
            height: 300px;
            max-height: 400px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 350px;
            }
        }
        .info-card {
            background-color: #FFFFFF;
            border: 1px solid #F3F4F6;
        }
        .pipeline-step {
            cursor: pointer;
            transition: background-color 0.2s;
        }
        .pipeline-step.active {
            background-color: #FEF3C7;
            border-color: #FBBF24;
        }
        .pipeline-arrow {
            color: #D1D5DB;
        }
        code {
            background-color: #F3F4F6;
            padding: 0.2em 0.4em;
            border-radius: 0.25rem;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
            font-size: 0.875em;
            /* color: #333333; Removed specific color for scripts */
        }
        pre {
            background-color: #F3F4F6;
            padding: 1rem;
            border-radius: 0.5rem;
            overflow-x: auto; /* Re-added scrollbar for pre */
            /* white-space: pre-wrap; Removed wrapping */
            /* word-wrap: break-word; Removed word wrap */
            /* overflow-x: hidden; Removed hidden overflow */
            /* color: #333333; Removed specific color for scripts */
        }
    </style>
</head>
<body class="antialiased">

    <div class="container mx-auto p-4 md:p-8 max-w-5xl">
        <header class="text-center mb-8">
            <h1 class="text-4xl font-bold text-gray-800 mb-2">Drowsiness Detection Project Wiki</h1>
            <p class="text-lg text-gray-600">A Comprehensive Workflow Guide</p>
        </header>

        <nav class="mb-8 border border-gray-200 rounded-lg p-4 bg-white shadow-sm">
            <h2 class="text-xl font-semibold text-gray-800 mb-4">Table of Contents</h2>
            <ul class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-2 text-gray-700">
                <li><a href="#project-tools-overview" class="nav-link block py-1 px-2 rounded hover:bg-gray-100" data-target="project-tools-overview">Project Tools Overview</a></li>
                <li><a href="#data-preparation" class="nav-link block py-1 px-2 rounded hover:bg-gray-100" data-target="data-preparation">1. Data Preparation</a></li>
                <li><a href="#model-configuration" class="nav-link block py-1 px-2 rounded hover:bg-gray-100" data-target="model-configuration">2. Model Configuration</a></li>
                <li><a href="#model-tuning" class="nav-link block py-1 px-2 rounded hover:bg-gray-100" data-target="model-tuning">3. Model Tuning</a></li>
                <li><a href="#local-deployment" class="nav-link block py-1 px-2 rounded hover:bg-gray-100" data-target="local-deployment">4. Local Deployment</a></li>
                <li><a href="#glossary" class="nav-link block py-1 px-2 rounded hover:bg-gray-100" data-target="glossary">Glossary</a></li>
            </ul>
        </nav>

        <main>
            <section id="project-tools-overview" class="content-section active">
                <h2 class="text-2xl font-semibold text-gray-800 mb-4">Project Tools Overview</h2>
                <p class="mb-6 text-gray-700">This section provides a concise overview of the primary libraries and tools utilized throughout the drowsiness detection project, outlining their specific roles in the workflow.</p>
                <div class="bg-white p-6 rounded-lg shadow-sm border border-gray-100">
                    <div class="overflow-x-auto">
                        <table class="min-w-full divide-y divide-gray-200">
                            <thead class="bg-gray-50">
                                <tr>
                                    <th scope="col" class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Task</th>
                                    <th scope="col" class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Primary Library/Tool</th>
                                    <th scope="col" class="px-6 py-3 text-left text-xs font-medium text-gray-500 uppercase tracking-wider">Purpose</th>
                                </tr>
                            </thead>
                            <tbody class="bg-white divide-y divide-gray-200">
                                <tr>
                                    <td class="px-6 py-4 whitespace-nowrap text-sm font-medium text-gray-900">Data Loading</td>
                                    <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-500">Pandas</td>
                                    <td class="px-6 py-4 text-sm text-gray-500">Efficiently load and manage time-series data.</td>
                                </tr>
                                <tr>
                                    <td class="px-6 py-4 whitespace-nowrap text-sm font-medium text-gray-900">Data Cleansing</td>
                                    <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-500">SciPy</td>
                                    <td class="px-6 py-4 text-sm text-gray-500">Apply filters to remove noise and isolate relevant signal components.</td>
                                </tr>
                                <tr>
                                    <td class="px-6 py-4 whitespace-nowrap text-sm font-medium text-gray-900">Scaling</td>
                                    <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-500">Scikit-learn</td>
                                    <td class="px-6 py-4 text-sm text-gray-500">Normalize feature values to a consistent range for model optimization.</td>
                                </tr>
                                <tr>
                                    <td class="px-6 py-4 whitespace-nowrap text-sm font-medium text-gray-900">Modeling</td>
                                    <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-500">Keras</td>
                                    <td class="px-6 py-4 text-sm text-gray-500">Construct, train, and evaluate the deep learning model.</td>
                                </tr>
                                <tr>
                                    <td class="px-6 py-4 whitespace-nowrap text-sm font-medium text-gray-900">Deployment</td>
                                    <td class="px-6 py-4 whitespace-nowrap text-sm text-gray-500">Streamlit</td>
                                    <td class="px-6 py-4 text-sm text-gray-500">Create a simple, interactive local graphical user interface.</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </section>

            <hr class="my-8 border-gray-200">

            <section id="data-preparation" class="content-section">
                <h2 class="text-2xl font-semibold text-gray-800 mb-4">1. Data Preparation ðŸ“Š</h2>
                <p class="mb-6 text-gray-700">Data preparation encompasses the processes required to transform raw sensor readings into a clean, usable format suitable for machine learning model ingestion.</p>

                <h3 class="text-xl font-semibold text-gray-800 mb-3">1.1. Data Loading and Initial Structure</h3>
                <p class="mb-4 text-gray-700">For prototyping, input data will originate from a tabular/CSV file, which should be time-stamped. In the final deployed system, data will be acquired directly from an ESP32 microcontroller, with the photodiode connected to its Analog-to-Digital Converter (ADC) pin. The MPU6050's Y-axis data, quantifying vertical head movements indicative of up-and-down nodding, will also be incorporated. The <strong>Pandas</strong> library is utilized for data loading.</p>
                <p class="mb-4 text-gray-700 font-semibold">Instruction:</p>
                <p class="mb-4 text-gray-700">Create a new Python file named <code class="text-sm">data_loader.py</code> in the project directory. Paste the following script into <code class="text-sm">data_loader.py</code> and execute it to load the dataset. Ensure column names in the script align with the actual data within your CSV file.</p>
                <pre><code class="language-python">import pandas as pd

# Load the dataset. Replace 'your_drowsiness_dataset.csv' with the actual file path.
# Ensure column names match the actual data (e.g., 'timestamp', 'photodiode_raw', 'mpu_y_raw')
df = pd.read_csv('your_drowsiness_dataset.csv')
df['timestamp'] = pd.to_datetime(df['timestamp']) # Convert timestamp column to datetime objects
df = df.set_index('timestamp') # Set timestamp as index for easier time-series operations
</code></pre>

                <h3 class="text-xl font-semibold text-gray-800 mb-3 mt-8">1.2. Signal Filtering</h3>
                <p class="mb-4 text-gray-700">Raw sensor signals frequently exhibit noise. Filtering techniques are employed to mitigate this noise and isolate pertinent patterns. The <strong>SciPy</strong> library is instrumental in this process.</p>
                <ul class="list-disc list-inside mb-4 text-gray-700">
                    <li><strong>Photodiode Signal:</strong>
                        <ul class="list-circle list-inside ml-4">
                            <li>A <strong>high-pass filter</strong> is applied to eliminate the slow-changing <strong>DC offset</strong> (background light levels), thereby accentuating the rapid variations characteristic of blinks.</li>
                            <li>A <strong>low-pass filter</strong> is utilized to smooth high-frequency electrical noise.</li>
                        </ul>
                    </li>
                    <li><strong>MPU6050 Y-axis Data:</strong>
                        <ul class="list-circle list-inside ml-4">
                            <li>A <strong>low-pass filter</strong> is applied to this data to attenuate minor jitters, consequently highlighting significant up-and-down head movements associated with nodding.</li>
                        </ul>
                    </li>
                </ul>
                <p class="mb-4 text-gray-700 font-semibold">Instruction:</p>
                <p class="mb-4 text-gray-700">Add the following filtering procedures to your <code class="text-sm">data_loader.py</code> script, immediately after the data loading section. Adjust <code class="text-sm">fs_pd</code> and <code class="text-sm">fs_mpu</code> to match the actual sampling rates of the respective sensors in the dataset.</p>
                <pre><code class="language-python">from scipy.signal import butter, filtfilt

# Example: Photodiode sampling frequency in Hz (adjust to dataset's actual rate)
fs_pd = 100
# Example: MPU6050 sampling frequency in Hz (adjust to dataset's actual rate)
fs_mpu = 50

# --- Photodiode Filtering ---
# High-pass filter settings (e.g., cutoff at 0.5 Hz to remove slow ambient changes)
b_high, a_high = butter(N=2, Wn=0.5, fs=fs_pd, btype='high')
df['photodiode_filtered_high'] = filtfilt(b_high, a_high, df['photodiode_raw'])

# Low-pass filter settings (e.g., cutoff at 10 Hz to remove high-frequency noise)
b_low, a_low = butter(N=2, Wn=10, fs=fs_pd, btype='low')
df['photodiode_final_filtered'] = filtfilt(b_low, a_low, df['photodiode_filtered_high'])

# --- MPU6050 Filtering ---
# Low-pass filter settings (e.g., cutoff at 5 Hz to smooth jitters)
b_mpu, a_mpu = butter(N=2, Wn=5, fs=fs_mpu, btype='low')
df['mpu_y_filtered'] = filtfilt(b_mpu, a_mpu, df['mpu_y_raw'])
</code></pre>


                <h3 class="text-xl font-semibold text-gray-800 mb-3 mt-8">1.3. Normalization (Scaling)</h3>
                <p class="mb-4 text-gray-700">Neural network performance is enhanced when input values are scaled to a compact, consistent range. <strong>MinMaxScaler</strong> from Scikit-learn is employed to scale features (blink rate, duration, nodding frequency) to a range between 0 and 1.</p>
                <p class="mb-4 text-gray-700 font-semibold">Instruction:</p>
                <p class="mb-4 text-gray-700">After extracting <code class="text-sm">features_raw</code> (as described in Section 1.4), add the following script to <code class="text-sm">data_loader.py</code> to apply the MinMaxScaler. Ensure the scaler is fitted exclusively on the training data to prevent data leakage. The <code class="text-sm">features_raw</code> variable will be a NumPy array derived from the processed data in the previous step (e.g., after feature extraction and windowing).</p>
                <pre><code class="language-python">from sklearn.preprocessing import MinMaxScaler
import numpy as np

# Assuming 'features_raw' is a NumPy array of extracted features.
# For example, if features are structured for 60-second windows:
# features_raw = np.array([[blink_rate_window1, duration_window1, nod_freq_window1],
#                          [blink_rate_window2, duration_duration2, nod_freq_window2], ...])

scaler = MinMaxScaler()
# Fit the scaler to training data and transform it.
scaled_features = scaler.fit_transform(features_raw)
# It is crucial to save this scaler for later use in the deployment phase
# import joblib
# joblib.dump(scaler, 'scaler.pkl')
</code></pre>
                <p class="mb-4 text-gray-700">This process adjusts values such that the minimum value becomes 0, the maximum becomes 1, and all intermediate values are scaled proportionally.</p>

                <h3 class="text-xl font-semibold text-gray-800 mb-3 mt-8">1.4. Feature Extraction & Drowsiness Score Labeling</h3>
                <p class="mb-4 text-gray-700">For each fixed-size time window (e.g., 60 seconds), simplified features are calculated, and a corresponding drowsiness score is assigned.</p>
                <ul class="list-disc list-inside mb-4 text-gray-700">
                    <li><strong>Blink Rate:</strong> This involves counting blinks in the <code class="text-sm">photodiode_final_filtered</code> signal, typically by detecting dips below a defined threshold. This requires custom logic for peak detection and thresholding.</li>
                    <li><strong>Average Blink Duration:</strong> The duration of each detected blink is measured, and these durations are averaged over the window. This also requires custom logic tied to blink detection.</li>
                    <li><strong>Nodding Frequency:</strong> This involves counting significant downward movements in the <code class="text-sm">mpu_y_filtered</code> data, indicative of head nods. This will require custom logic for identifying significant movements (e.g., based on acceleration peaks or changes).</li>
                </ul>
                <p class="mb-4 text-gray-700">Subsequently, a function is utilized to assign a <strong>drowsiness score (0-1)</strong> based on these extracted features.</p>
                <p class="mb-4 text-gray-700 font-semibold">Instruction:</p>
                <p class="mb-4 text-gray-700">Implement functions for blink and nodding detection within <code class="text-sm">data_loader.py</code> (or a new file like <code class="text-sm">feature_extractor.py</code>). These functions will process the filtered data (<code class="text-sm">df['photodiode_final_filtered']</code> and <code class="text-sm">df['mpu_y_filtered']</code>) within defined time windows. The output will be a NumPy array, <code class="text-sm">features_raw</code>, where each row represents a window's features, and a corresponding <code class="text-sm">y_labels</code> array for the drowsiness scores.</p>
                <pre><code class="language-python"># This is a conceptual function. Actual blink/nod detection logic
# will be implemented, and the calculated features will then be passed into a function like this.
def calculate_drowsiness_score(blink_rate, avg_blink_duration, nodding_frequency):
    score = 0.0

    # Illustrative rules (these will require refinement based on empirical data)
    if blink_rate &lt; 10: # A lower blink rate may indicate drowsiness
        score += 0.3
    if avg_blink_duration &gt; 0.4: # Longer blinks may indicate drowsiness
        score += 0.4
    if nodding_frequency &gt; 0: # Any detected nodding indicates drowsiness
        score += 0.3

    # The score is constrained to remain within the 0 to 1 range
    score = max(0.0, min(1.0, score))

    return score

# Example placeholder for feature extraction and labeling process:
# features_list = []
# labels_list = []
# window_size_samples = 60 * fs_pd # e.g., 60 seconds * 100 Hz = 6000 samples
# for i in range(0, len(df), window_size_samples):
#     window_df = df.iloc[i:i + window_size_samples]
#     if len(window_df) == window_size_samples: # Ensure full window
#         # Implement your custom blink and nod detection here
#         # For example:
#         # current_blink_rate = your_blink_detection_function(window_df['photodiode_final_filtered'])
#         # current_avg_blink_duration = your_duration_function(window_df['photodiode_final_filtered'])
#         # current_nodding_frequency = your_nod_detection_function(window_df['mpu_y_filtered'])
#
#         # For now, use placeholder values or a simple derivation
#         current_blink_rate = 15 # Placeholder
#         current_avg_blink_duration = 0.2 # Placeholder
#         current_nodding_frequency = 0 # Placeholder
#
#         features_list.append([current_blink_rate, current_avg_blink_duration, current_nodding_frequency])
#         labels_list.append(calculate_drowsiness_score(current_blink_rate, current_avg_blink_duration, current_nodding_frequency))
#
# features_raw = np.array(features_list)
# y_labels = np.array(labels_list)
</code></pre>

                <h3 class="text-xl font-semibold text-gray-800 mb-3 mt-8">1.5. Prepare for LSTM Input</h3>
                <p class="mb-4 text-gray-700">Data must be shaped as <code class="text-sm">(number_of_windows, time_steps_per_window, number_of_features)</code>. For instance, if features are calculated once per second over a 60-second window, <code class="text-sm">time_steps_per_window</code> would be 60, and <code class="text-sm">number_of_features</code> would be 3 (blink rate, average blink duration, nodding frequency).</p>
                <p class="mb-4 text-gray-700 font-semibold">Instruction:</p>
                <p class="mb-4 text-gray-700">Reshape the prepared <code class="text-sm">scaled_features</code> data into the required 3D format for LSTM input. This step should also be part of your <code class="text-sm">data_loader.py</code> or a dedicated <code class="text-sm">feature_processor.py</code>, ensuring <code class="text-sm">X</code> and <code class="text-sm">y</code> are ready for model training.</p>
                <pre><code class="language-python"># Assuming 'scaled_features' is the output from Section 1.3
# and 'y_labels' is the output from Section 1.4

# Define the number of time steps per window and number of features
# This depends on how you extracted features in Section 1.4
# For example, if you extracted one feature vector per 60-second window, then time_steps_per_window = 1
# If you extracted features every second for 60 seconds, then time_steps_per_window = 60
time_steps_per_window = 1 # Adjust based on your feature extraction strategy
num_features = scaled_features.shape[1] # Number of features (e.g., 3: blink rate, avg duration, nod freq)

# Reshape the features into 3D for LSTM input
# The first dimension is the number of samples/windows
X = scaled_features.reshape(-1, time_steps_per_window, num_features)
y = y_labels # Your drowsiness scores

# Now X and y are ready for train_test_split and model training
</code></pre>
            </section>

            <hr class="my-8 border-gray-200">

            <a id="model-configuration"></a>
            <section class="content-section">
                <h2 class="text-2xl font-semibold text-gray-800 mb-4">2. Model Configuration (Keras LSTM Regression) ðŸ§±</h2>
                <p class="mb-6 text-gray-700">This section details the definition of the machine learning model utilizing Keras.</p>

                <h3 class="text-xl font-semibold text-gray-800 mb-3">2.1. Install Keras and TensorFlow</h3>
                <p class="mb-4 text-gray-700 font-semibold">Instruction:</p>
                <p class="mb-4 text-gray-700">Open the VS Code integrated terminal (with the virtual environment activated) and execute the following command to install Keras and its underlying framework TensorFlow:</p>
                <pre><code class="language-bash">pip install tensorflow
</code></pre>
                <p class="mb-4 text-gray-700">This command installs TensorFlow, which incorporates Keras as <code class="text-sm">tf.keras</code>.</p>

                <h3 class="text-xl font-semibold text-gray-800 mb-3 mt-8">2.2. Build the Model Architecture</h3>
                <p class="mb-4 text-gray-700">A <strong>Sequential</strong> Keras model will be constructed, comprising an LSTM layer, a Dropout layer, and a Dense output layer.</p>
                <p class="mb-4 text-gray-700 font-semibold">Instruction:</p>
                <p class="mb-4 text-gray-700">Create a new Python file named <code class="text-sm">model_builder.py</code>. Paste the following script into <code class="text-sm">model_builder.py</code> to define the model architecture. Ensure <code class="text-sm">input_shape</code> matches the dimensions of the prepared data from Section 1.5.</p>
                <pre><code class="language-python">from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

# Assuming X is the 3D feature array and y is the 1D drowsiness score array
# Data is split into training and validation sets (e.g., 80% for training, 20% for validation)
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Model definition
model = Sequential([
    # LSTM layer: 50 units, 'relu' activation, input shape matches data (timesteps, features)
    LSTM(units=50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),
    # Dropout layer: 20% of neurons are randomly deactivated during training to prevent overfitting
    Dropout(0.2),
    # Output layer: 1 unit for regression, 'sigmoid' activation for 0-1 score
    Dense(units=1, activation='sigmoid')
])
</code></pre>


                <h3 class="text-xl font-semibold text-gray-800 mb-3 mt-8">2.3. Compile the Model</h3>
                <p class="mb-4 text-gray-700">Subsequent to layer definition, the model must be <strong>compiled</strong>. This step configures the learning process.</p>
                <p class="mb-4 text-gray-700 font-semibold">Instruction:</p>
                <p class="mb-4 text-gray-700">Add the following compilation script to <code class="text-sm">model_builder.py</code>, immediately after the model definition.</p>
                <pre><code class="language-python"># Model compilation
model.compile(optimizer=Adam(learning_rate=0.001), # Adam optimizer with an initial learning rate
              loss='mean_squared_error',           # MSE for regression
              metrics=['mean_absolute_error'])     # MAE for easy interpretation

# A summary of the model's layers and parameters is displayed
model.summary()
</code></pre>
            </section>

            <hr class="my-8 border-gray-200">

            <a id="model-tuning"></a>
            <section class="content-section">
                <h2 class="text-2xl font-semibold text-gray-800 mb-4">3. Model Tuning (Iterative Refinement) ðŸ§ª</h2>
                <p class="mb-6 text-gray-700">Initial model performance is rarely optimal. Tuning involves systematically adjusting parameters to enhance performance.</p>

                <h3 class="text-xl font-semibold text-gray-800 mb-3">3.1. Train the Model</h3>
                <p class="mb-4 text-gray-700 font-semibold">Instruction:</p>
                <p class="mb-4 text-gray-700">Create a new Python file named <code class="text-sm">train_model.py</code>. Paste the following script into <code class="text-sm">train_model.py</code>. Ensure that <code class="text-sm">X_train</code>, <code class="text-sm">y_train</code>, <code class="text-sm">X_val</code>, and <code class="text-sm">y_val</code> are available (e.g., by importing them from <code class="text-sm">data_loader.py</code> or by running <code class="text-sm">data_loader.py</code> first to generate them). Execute this script in the VS Code terminal to initiate model training.</p>
                <pre><code class="language-python"># Assuming X_train, y_train, X_val, y_val are already defined from data splitting
history = model.fit(
    X_train, y_train,
    epochs=50,       # Initial number of training epochs
    batch_size=32,   # Batch size for training
    validation_data=(X_val, y_val) # Data utilized for performance evaluation during training
)
</code></pre>

                <h3 class="text-xl font-semibold text-gray-800 mb-3 mt-8">3.2. Monitor Performance</h3>
                <p class="mb-4 text-gray-700 font-semibold">Instruction:</p>
                <p class="mb-4 text-gray-700">During the training phase, closely monitor the <code class="text-sm">val_mean_absolute_error</code> (validation MAE) displayed in the terminal. This metric indicates the model's performance on data not encountered during training. The objective is to **minimize this value**.</p>

                <h3 class="text-xl font-semibold text-gray-800 mb-3 mt-8">3.3. Model Tuning: Parameter Impact</h3>
                <p class="mb-4 text-gray-700">This section outlines how adjusting specific model parameters can influence training behavior and overall performance. These adjustments are made within the development script (e.g., <code class="text-sm">model_builder.py</code>) and require re-running the training process to observe their effects.</p>

                <div class="grid md:grid-cols-2 gap-8 items-center mb-6">
                    <div>
                        <h4 class="text-lg font-semibold mb-3">Tune Model Parameters</h4>
                        <div class="space-y-4">
                            <div>
                                <label for="learningRate" class="block text-sm font-medium text-gray-700">Learning Rate</label>
                                <select id="learningRate" class="mt-1 block w-full pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-amber-500 focus:border-amber-500 sm:text-sm rounded-md">
                                    <option value="0.01">0.01 (High)</option>
                                    <option value="0.001" selected>0.001 (Default)</option>
                                    <option value="0.0001">0.0001 (Low)</option>
                                </select>
                                <p class="text-xs text-gray-600 mt-1">Controls the step size for weight adjustments. Smaller values lead to slower but potentially more stable training. Larger values can speed up training but risk instability.</p>
                            </div>
                            <div>
                                <label for="lstmUnits" class="block text-sm font-medium text-gray-700">LSTM Units</label>
                                <select id="lstmUnits" class="mt-1 block w-full pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-amber-500 focus:border-amber-500 sm:text-sm rounded-md">
                                    <option value="32">32 (Low Complexity)</option>
                                    <option value="50" selected>50 (Default)</option>
                                    <option value="100">100 (High Complexity)</option>
                                </select>
                                <p class="text-xs text-gray-600 mt-1">Determines the capacity of the LSTM layer. More units allow learning of intricate patterns but increase complexity and risk overfitting. Fewer units reduce complexity.</p>
                            </div>
                            <div>
                                <label for="dropoutRate" class="block text-sm font-medium text-gray-700">Dropout Rate</label>
                                <select id="dropoutRate" class="mt-1 block w-full pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-amber-500 focus:border-amber-500 sm:text-sm rounded-md">
                                    <option value="0.0">0.0 (None)</option>
                                    <option value="0.2" selected>0.2 (Default)</option>
                                    <option value="0.5">0.5 (High)</option>
                                </select>
                                <p class="text-xs text-gray-600 mt-1">Proportion of neurons randomly deactivated during training. Higher rates mitigate overfitting but can impede learning if too high.</p>
                            </div>
                        </div>
                    </div>
                    <div class="chart-container">
                        <canvas id="tuningChart"></canvas>
                    </div>
                </div>

                <ul class="list-disc list-inside mb-4 text-gray-700">
                    <li><strong>Adjusting <code class="text-sm">epochs</code>:</strong>
                        <ul class="list-circle list-inside ml-4">
                            <li><strong>Behavior Change:</strong> Controls the total training duration. Increasing epochs provides more opportunities for the model to learn patterns.</li>
                            <li><strong>Expected Output:</strong> If <code class="text-sm">val_mean_absolute_error</code> continues to decrease, increasing <code class="text-sm">epochs</code> may improve accuracy. If <code class="text-sm">val_mean_absolute_error</code> begins to increase, reducing <code class="text-sm">epochs</code> is necessary to prevent **overfitting**.</li>
                        </ul>
                    </li>
                    <li><strong>Adjusting <code class="text-sm">learning_rate</code> (within <code class="text-sm">Adam</code> optimizer):</strong>
                        <ul class="list-circle list-inside ml-4">
                            <li><strong>Behavior Change:</strong> Dictates the magnitude of adjustments made to the model's internal weights during optimization.</li>
                            <li><strong>Expected Output:</strong> A **smaller learning rate** (e.g., <code class="text-sm">0.0005</code> or <code class="text-sm">0.0001</code>) can lead to more stable training and potentially better accuracy if the current rate is too high. A **larger learning rate** can speed up training but may cause erratic loss fluctuations or prevent convergence.</li>
                            <li><strong>Instruction:</strong> Modify <code class="text-sm">learning_rate</code> in the <code class="text-sm">Adam</code> optimizer within <code class="text-sm">model_builder.py</code> as needed.</li>
                            <pre><code class="language-python">model.compile(optimizer=Adam(learning_rate=0.0005), # Example: changed from 0.001
              loss='mean_squared_error',
              metrics=['mean_absolute_error'])
</code></pre>
                        </ul>
                    </li>
                    <li><strong>Adjusting <code class="text-sm">LSTM units</code>:</strong>
                        <ul class="list-circle list-inside ml-4">
                            <li><strong>Behavior Change:</strong> Determines the capacity of the LSTM layer. A greater number of units enables the model to learn more intricate patterns.</li>
                            <li><strong>Expected Output:</strong> **Increasing units** (e.g., from 50 to 75 or 100) may improve learning for complex patterns, potentially lowering <code class="text-sm">val_mean_absolute_error</code>. **Decreasing units** may be necessary if overfitting occurs rapidly, as fewer units reduce model complexity.</li>
                            <li><strong>Instruction:</strong> Modify <code class="text-sm">units</code> in the <code class="text-sm">LSTM</code> layer within <code class="text-sm">model_builder.py</code> as needed.</li>
                            <pre><code class="language-python">LSTM(units=75, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])), # Example: changed from 50
</code></pre>
                        </ul>
                    </li>
                    <li><strong>Adjusting <code class="text-sm">Dropout</code> rate:</strong>
                        <ul class="list-circle list-inside ml-4">
                            <li><strong>Behavior Change:</strong> Controls the proportion of neurons randomly deactivated during training, acting as a regularization technique.</li>
                            <li><strong>Expected Output:</strong> **Increasing the dropout rate** (e.g., from 0.2 to 0.3 or 0.4) can help mitigate **overfitting** by forcing the model to learn more robust features. However, an excessively high rate can impede effective learning, potentially increasing <code class="text-sm">val_mean_absolute_error</code>.</li>
                            <li><strong>Instruction:</strong> Modify <code class="text-sm">rate</code> in the <code class="text-sm">Dropout</code> layer within <code class="text-sm">model_builder.py</code> as needed.</li>
                            <pre><code class="language-python">Dropout(0.3), # Example: changed from 0.2
</code></pre>
                        </ul>
                    </li>
                </ul>
            </section>

            <hr class="my-8 border-gray-200">

            <a id="local-deployment"></a>
            <section class="content-section">
                <h2 class="text-2xl font-semibold text-gray-800 mb-4">4. Local Deployment (Simple Streamlit GUI) ðŸš€</h2>
                <p class="mb-6 text-gray-700">Upon satisfactory model tuning and performance, the model will be saved, and a simple local application will be created.</p>

                <h3 class="text-xl font-semibold text-gray-800 mb-3">4.1. Save the Tuned Model</h3>
                <p class="mb-4 text-gray-700 font-semibold">Instruction:</p>
                <p class="mb-4 text-gray-700">After training and tuning, add the following line to your <code class="text-sm">train_model.py</code> script to save the model.</p>
                <pre><code class="language-python">model.save('drowsiness_detector.h5')
</code></pre>

                <h3 class="text-xl font-semibold text-gray-800 mb-3 mt-8">4.2. Build the Streamlit Application</h3>
                <p class="mb-4 text-gray-700">A new Python file (e.g., <code class="text-sm">app.py</code>) will be created. This script will load the saved model and establish a straightforward web-based user interface that operates locally.</p>
                <p class="mb-4 text-gray-700 font-semibold">Instruction:</p>
                <p class="mb-4 text-gray-700">Create a new Python file named <code class="text-sm">app.py</code>. Paste the following script into <code class="text-sm">app.py</code>.</p>
                <pre><code class="language-python">import streamlit as st
import tensorflow as tf
import numpy as np

# Load the trained model once when the app starts
@st.cache_resource # This decorator prevents the model from reloading every time Streamlit reruns
def load_drowsiness_model():
    try:
        model = tf.keras.models.load_model('drowsiness_detector.h5')
        return model
    except Exception as e:
        st.error(f"Error loading model: {e}. Make sure 'drowsiness_detector.h5' is in the same directory.")
        return None

model = load_drowsiness_model()

st.title("Drowsiness Detection Prototype ðŸ˜´")
st.write("Enter sensor feature values to get a drowsiness prediction (0 = Alert, 1 = Asleep).")

if model:
    # Input widgets for your simplified features
    blink_rate = st.slider("Blink Rate (blinks/min)", 0, 30, 15)
    avg_blink_duration = st.slider("Average Blink Duration (seconds)", 0.0, 1.0, 0.2, 0.05)
    nodding_frequency = st.slider("Nodding Frequency (nods/min)", 0, 5, 0)

    if st.button("Predict Drowsiness"):
        # Prepare input for the model (must match training input shape)
        # For this simple example, we'll just use a single timestep with the 3 features
        # In a real scenario, you'd collect a 60-second window of these features

        input_features = np.array([[blink_rate, avg_blink_duration, nodding_frequency]])

        # Reshape for LSTM input (samples, timesteps, features)
        # For this prototype, we're using 1 timestep for direct input
        model_input = input_features.reshape(1, 1, 3) # (1 sample, 1 timestep, 3 features)

        drowsiness_score = model.predict(model_input)[0][0] # Get the single score

        st.subheader(f"Predicted Drowsiness Score: {drowsiness_score:.2f}")

        if drowsiness_score < 0.3:
            st.success("Status: Alert ðŸ˜Š")
        elif drowsiness_score < 0.7:
            st.warning("Status: Drowsy ðŸ˜´")
        else:
            st.error("Status: Severely Drowsy (Asleep) ðŸ’¤")
else:
    st.write("Model not loaded. Please check the console for errors.")
```</pre>
                <p class="mb-4 text-gray-700 font-semibold">Instruction:</p>
                <p class="mb-4 text-gray-700">To execute the Streamlit application, navigate to the project directory in the VS Code terminal and run:</p>
                <pre><code class="language-bash">streamlit run app.py
</code></pre>
                <p class="mb-4 text-gray-700">This command will launch a new tab in the web browser, presenting the interactive drowsiness predictor. It will facilitate the input (or simulation) of the three features and display the predicted drowsiness score.</p>
            </section>

            <hr class="my-8 border-gray-200">

            <a id="glossary"></a>
            <section class="content-section">
                <h2 class="text-2xl font-semibold text-gray-800 mb-4">Glossary ðŸ“š</h2>
                <ul class="list-disc list-inside space-y-2 text-gray-700">
                    <li><strong>ADC (Analog-to-Digital Converter):</strong> Converts analog signals to digital values.</li>
                    <li><strong>Pandas:</strong> Python library for data manipulation and analysis, using DataFrames.</li>
                    <li><strong>SciPy:</strong> Python library for scientific computing, including signal processing functions.</li>
                    <li><strong>High-pass filter:</strong> Passes high frequencies, attenuates low frequencies (removes DC offset).</li>
                    <li><strong>Low-pass filter:</strong> Passes low frequencies, attenuates high frequencies (smoothes noise).</li>
                    <li><strong>Normalization (Scaling):</strong> Transforms data to a specific range (e.g., 0-1) for consistent input.</li>
                    <li><strong>MinMaxScaler:</strong> A Scikit-learn scaler that normalizes features to a specified range.</li>
                    <li><strong>Features:</strong> Measurable characteristics of observed phenomena (e.g., blink rate, nodding frequency).</li>
                    <li><strong>Time Window:</strong> A fixed segment of a continuous data stream for analysis.</li>
                    <li><strong>Keras:</strong> High-level API for building and training deep learning models.</li>
                    <li><strong>TensorFlow:</strong> Open-source machine learning framework, often serving as Keras's backend.</li>
                    <li><strong>Sequential Model:</strong> A linear stack of neural network layers in Keras.</li>
                    <li><strong>LSTM (Long Short-Term Memory) Layer:</strong> Recurrent neural network layer adept at learning patterns in sequential data.</li>
                    <li><strong>Dropout Layer:</strong> Regularization technique that randomly deactivates neurons during training to prevent overfitting.</li>
                    <li><strong>Dense Layer:</strong> Fully connected neural network layer where each neuron connects to all neurons in the preceding layer.</li>
                    <li><strong>Optimizer (Adam):</strong> Algorithm that adjusts model weights to minimize the loss function during training.</li>
                    <li><strong>Learning Rate:</strong> Hyperparameter controlling the step size for weight adjustments during optimization.</li>
                    <li><strong>Loss Function (Mean Squared Error - MSE):</strong> Quantifies the difference between predicted and true values for regression tasks.</li>
                    <li><strong>Metrics (Mean Absolute Error - MAE):</strong> Evaluates regression model performance by averaging absolute prediction errors.</li>
                    <li><strong>Epochs:</strong> One complete pass of the entire training dataset through the neural network.</li>
                    <li><strong>Batch Size:</strong> Number of training examples processed before a model's weights are updated.</li>
                    <li><strong>Overfitting:</strong> Model learns training data too well, leading to poor performance on new data.</li>
                    <li><strong>Streamlit:</strong> Python library for creating interactive web applications for machine learning models.</li>
                </ul>
            </section>
        </main>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const navLinks = document.querySelectorAll('.nav-link');
            const contentSections = document.querySelectorAll('.content-section');
            const pipelineSteps = document.querySelectorAll('.pipeline-step');

            const pipelineDetailsContent = {
                load: {
                    title: '1. Load & Structure Data',
                    text: 'The process begins by loading the time-stamped CSV data using the <strong>Pandas</strong> library. The timestamp is set as the index to facilitate time-series operations, creating a structured DataFrame as the foundation for all subsequent steps.'
                },
                filter: {
                    title: '2. Signal Filtering',
                    text: 'Raw sensor data is noisy. Using <strong>SciPy</strong>, a high-pass filter removes slow ambient light drift from the photodiode signal, while low-pass filters smooth out high-frequency noise and jitters from both the photodiode and MPU6050 signals, isolating clear patterns for blinks and nods.'
                },
                features: {
                    title: '3. Feature Extraction & Labeling',
                    text: 'The continuous, filtered data is segmented into fixed-time windows (e.g., 60 seconds). For each window, we calculate meaningful features: <strong>Blink Rate</strong>, <strong>Average Blink Duration</strong>, and <strong>Nodding Frequency</strong>. A custom function then assigns a drowsiness score (0-1) to each window based on these features.'
                },
                scale: {
                    title: '4. Scale & Reshape for Model',
                    text: 'Neural networks perform best with normalized data. <strong>Scikit-learn\'s MinMaxScaler</strong> scales all extracted features to a consistent 0-1 range. The data is then reshaped into a 3D array `(samples, timesteps, features)` required by the LSTM model.'
                }
            };

            function updatePipelineDetails(stepId) {
                const content = pipelineDetailsContent[stepId];
                const pipelineDetailsElement = document.getElementById('pipeline-details');
                if (pipelineDetailsElement) { // Check if the element exists
                    pipelineDetailsElement.innerHTML = `
                        <h4 class="font-semibold text-lg mb-2">${content.title}</h4>
                        <p class="text-sm">${content.text}</p>
                    `;
                }
                pipelineSteps.forEach(step => {
                    step.classList.remove('active');
                    if(step.id === `step-${stepId}`) {
                        step.classList.add('active');
                    }
                });
            }

            function showSection(targetId) {
                contentSections.forEach(section => {
                    section.classList.remove('active');
                });
                const targetSection = document.getElementById(targetId);
                if (targetSection) {
                    targetSection.classList.add('active');
                    // Scroll to the top of the section, if needed
                    targetSection.scrollIntoView({ behavior: 'smooth', block: 'start' });
                }

                // Update active state of nav links
                navLinks.forEach(link => {
                    if (link.getAttribute('data-target') === targetId) {
                        link.classList.add('nav-link-active'); // Add a new class for active nav link
                    } else {
                        link.classList.remove('nav-link-active');
                    }
                });
            }

            // Initial display: show the first section
            showSection('project-tools-overview');
            // Check if pipeline-details exists before calling updatePipelineDetails
            if (document.getElementById('pipeline-details')) {
                updatePipelineDetails('load'); // Initialize pipeline details
            }


            navLinks.forEach(link => {
                link.addEventListener('click', function(event) {
                    event.preventDefault(); // Prevent default anchor jump
                    const targetId = this.getAttribute('data-target');
                    showSection(targetId);
                });
            });


            pipelineSteps.forEach(step => {
                step.addEventListener('click', () => {
                    const stepId = step.id.split('-')[1];
                    updatePipelineDetails(stepId);
                });
            });

            const tuningCtx = document.getElementById('tuningChart').getContext('2d');
            let tuningChart;

            const baseMAE = {
                '0.01': 0.25, '0.001': 0.15, '0.0001': 0.18,
                '32': 0.03, '50': 0, '100': -0.02,
                '0.0': 0.04, '0.2': 0, '0.5': 0.02
            };

            function updateTuningChart() {
                const lr = document.getElementById('learningRate').value;
                const units = document.getElementById('lstmUnits').value;
                const dropout = document.getElementById('dropoutRate').value;

                const defaultMAE = 0.15;
                const lrEffect = baseMAE[lr];
                const unitsEffect = baseMAE[units];
                const dropoutEffect = baseMAE[dropout];

                const finalMAE = defaultMAE - lrEffect + unitsEffect + dropoutEffect;

                const data = {
                    labels: ['Mean Absolute Error (MAE)'],
                    datasets: [{
                        label: 'Model Performance',
                        data: [finalMAE],
                        backgroundColor: ['rgba(217, 119, 6, 0.6)'],
                        borderColor: ['rgba(217, 119, 6, 1)'],
                        borderWidth: 1
                    }]
                };

                if (tuningChart) {
                    tuningChart.data = data;
                    tuningChart.update();
                } else {
                    tuningChart = new Chart(tuningCtx, {
                        type: 'bar',
                        data: data,
                        options: {
                            responsive: true,
                            maintainAspectRatio: false,
                            scales: {
                                y: {
                                    beginAtZero: true,
                                    max: 0.5,
                                    title: { display: true, text: 'Validation MAE (Lower is Better)' }
                                }
                            },
                            plugins: {
                                legend: { display: false },
                                title: { display: true, text: 'Simulated Impact of Tuning' }
                            }
                        }
                    });
                }
            }

            // Ensure tuning chart elements exist before attaching listeners or updating
            if (document.getElementById('learningRate')) {
                document.getElementById('learningRate').addEventListener('change', updateTuningChart);
                document.getElementById('lstmUnits').addEventListener('change', updateTuningChart);
                document.getElementById('dropoutRate').addEventListener('change', updateTuningChart);
                updateTuningChart();
            }


            const blinkRateSlider = document.getElementById('blinkRate');
            const blinkDurationSlider = document.getElementById('blinkDuration');
            const nodFrequencySlider = document.getElementById('nodFrequency');
            const predictBtn = document.getElementById('predictBtn');
            const resultDiv = document.getElementById('predictionResult');

            // Ensure prototype elements exist before attaching listeners
            if (blinkRateSlider && blinkDurationSlider && nodFrequencySlider && predictBtn && resultDiv) {
                blinkRateSlider.addEventListener('input', (e) => {
                    document.getElementById('blinkRateValue').textContent = e.target.value;
                });
                blinkDurationSlider.addEventListener('input', (e) => {
                    document.getElementById('blinkDurationValue').textContent = parseFloat(e.target.value).toFixed(2);
                });
                nodFrequencySlider.addEventListener('input', (e) => {
                    document.getElementById('nodFrequencyValue').textContent = e.target.value;
                });

                predictBtn.addEventListener('click', () => {
                    const blinkRate = parseInt(blinkRateSlider.value);
                    const blinkDuration = parseFloat(blinkDurationSlider.value);
                    const nodFrequency = parseInt(nodFrequencySlider.value);

                    let score = 0.0;
                    if (blinkRate < 10) score += 0.3;
                    if (blinkDuration > 0.4) score += 0.4;
                    if (nodFrequency > 0) score += 0.3 + (nodFrequency * 0.1);

                    score = Math.max(0.0, Math.min(1.0, score));

                    let statusText = '';
                    let statusColor = '';
                    let statusEmoji = '';

                    if (score < 0.3) {
                        statusText = 'Alert';
                        statusColor = 'text-green-600';
                        statusEmoji = 'ðŸ˜Š';
                    } else if (score < 0.7) {
                        statusText = 'Drowsy';
                        statusColor = 'text-yellow-600';
                        statusEmoji = 'ðŸ˜´';
                    } else {
                        statusText = 'Severely Drowsy';
                        statusColor = 'text-red-600';
                        statusEmoji = 'ðŸ’¤';
                    }

                    resultDiv.innerHTML = `
                        <h3 class="text-lg font-medium text-gray-600">Predicted Score</h3>
                        <p class="text-5xl font-bold text-gray-800 my-4">${score.toFixed(2)}</p>
                        <p class="text-xl font-semibold ${statusColor}">${statusText} ${statusEmoji}</p>
                    `;
                });
            }
        });
    </script>
</body>
</html>
