<!-- Drowsiness Detection Project Wiki (Structured Markdown Version, CNN+LSTM Update) -->
<style>
  body { background: #f8fafc; font-family: 'Segoe UI', Arial, sans-serif; }
  .container { background: #fff; border-radius: 12px; box-shadow: 0 2px 8px #0001; padding: 32px; margin: 32px auto; }
  h1 { color: #1e293b; font-size: 2.5rem; margin-bottom: 0.5rem; letter-spacing: 1px; }
  h2 { color: #334155; font-size: 1.5rem; margin-top: 2rem; margin-bottom: 1rem; border-bottom: 1px solid #e2e8f0; padding-bottom: 0.25rem; }
  h3 { color: #475569; font-size: 1.15rem; margin-top: 1.5rem; margin-bottom: 0.5rem; }
  p { color: #374151; font-size: 1rem; line-height: 1.7; margin-bottom: 1rem; }
  ul { margin-left: 1.5rem; margin-bottom: 1rem; }
  li { margin-bottom: 0.5rem; color: #475569; }
  pre { background: #f1f5f9; border-radius: 8px; padding: 1rem; margin-bottom: 1.5rem; overflow-x: auto; }
  code { font-family: 'Fira Mono', 'Consolas', monospace; font-size: 0.98rem; color: #0f172a; }
  hr { border: none; border-top: 1px solid #e2e8f0; margin: 2rem 0; }
  .list-disc li strong { color: #2563eb; }
  .toc { background: #f1f5f9; border-radius: 8px; padding: 1rem 1.5rem; margin-bottom: 2rem; }
  .toc-title { font-weight: bold; color: #334155; margin-bottom: 0.5rem; }
  .toc-list { list-style: none; padding-left: 0; }
  .toc-list li { margin-bottom: 0.4rem; }
  .toc-list a { color: #2563eb; text-decoration: none; font-weight: 500; }
  .toc-list a:hover { text-decoration: underline; }
  .pipeline-diagram { display: flex; flex-wrap: wrap; justify-content: center; align-items: center; margin-bottom: 2rem; gap: 0.5rem; max-width: 100%; overflow-x: auto; }
  .pipeline-box { background: #e0e7ef; border-radius: 8px; padding: 0.75rem 1.5rem; margin: 0; color: #334155; font-weight: 500; box-shadow: 0 1px 4px #0001; transition: background 0.2s; white-space: nowrap; }
  .pipeline-arrow { font-size: 1.5rem; color: #2563eb; margin: 0; }
  .pipeline-box:hover { background: #c7d2fe; }
</style>
<div class="container">
  <div class="toc">
    <div class="toc-title">Table of Contents</div>
    <ul class="toc-list">
      <li><a href="#overview">Project Overview</a></li>
      <li><a href="#acquisition">1. Data Acquisition</a></li>
      <li><a href="#cleansing">2. Data Cleansing</a></li>
      <li><a href="#features">3. Feature Extraction</a></li>
      <li><a href="#modeling">4. Deep Learning Modeling (CNN+LSTM)</a></li>
      <li><a href="#tuning">5. Model Tuning</a></li>
      <li><a href="#storage">6. Data Storage</a></li>
      <li><a href="#deployment">7. Deployment & Visualization</a></li>
      <li><a href="#concerns">8. Areas of Concern and Research</a></li>
      <li><a href="#glossary">Glossary</a></li>
    </ul>
  </div>
  <div class="pipeline-diagram">
    <a href="#acquisition" class="pipeline-box" title="Go to Data Acquisition">Acquisition</a>
    <span class="pipeline-arrow">→</span>
    <a href="#cleansing" class="pipeline-box" title="Go to Data Cleansing">Cleansing</a>
    <span class="pipeline-arrow">→</span>
    <a href="#features" class="pipeline-box" title="Go to Feature Extraction">Features</a>
    <span class="pipeline-arrow">→</span>
    <a href="#modeling" class="pipeline-box" title="Go to Modeling">Modeling (CNN+LSTM)</a>
    <span class="pipeline-arrow">→</span>
    <a href="#tuning" class="pipeline-box" title="Go to Tuning">Tuning</a>
    <span class="pipeline-arrow">→</span>
    <a href="#storage" class="pipeline-box" title="Go to Storage">Storage</a>
    <span class="pipeline-arrow">→</span>
    <a href="#deployment" class="pipeline-box" title="Go to Deployment">Deployment</a>
  </div>
  <section>
    <h1 id="overview">Drowsiness Detection Project Wiki (Structured)</h1>
    <h2 id="overview">Project Overview</h2>
    <p>
      This project builds two independent deep learning models for drowsiness detection in users wearing IRIS glasses. Data is transmitted from an IoT device via Bluetooth, split into photodiode (blinking) and head movement (accelerometer) sets, cleansed, and fed to separate CNN+LSTM models. Each model outputs a drowsiness score (0.1–0.9) for real-time monitoring and classification.
    </p>
    <hr>
    <h2 id="acquisition">1. Data Acquisition</h2>
    <h3>1.1 Head Movement (Accelerometer)</h3>
    <p>
      Accelerometer data is collected from the IoT device, measuring vertical head movement (Y-axis). Sampling at a fixed rate (e.g., 50 Hz) captures nodding and tilting patterns. Data is stored in CSV format for reproducibility and analysis.
    </p>
    <h4>Process Description</h4>
    <p>
      The following code loads Y-axis acceleration data from a CSV file. This prepares the raw sensor data for cleansing and feature extraction.
    </p>
    <pre><code>
import pandas as pd
head_df = pd.read_csv('headmovement.csv')  # Load CSV with 'accel_y' column
y_accel = head_df['accel_y']               # Extract Y-axis acceleration
    </code></pre>
    <h3>1.2 Blinking (Photodiode)</h3>
    <p>
      Photodiode data is collected to measure blinking events. The sensor records ADC values representing light intensity changes caused by eyelid movement. Data is sampled at the same rate as the accelerometer and stored in CSV format.
    </p>
    <h4>Process Description</h4>
    <p>
      The code below loads photodiode ADC data from a CSV file, preparing the raw signal for cleansing and feature extraction.
    </p>
    <pre><code>
blink_df = pd.read_csv('blinking.csv')     # Load CSV with 'photodiode' column
pd_signal = blink_df['photodiode']         # Extract photodiode ADC values
    </code></pre>
    <hr>
    <h2 id="cleansing">2. Data Cleansing</h2>
    <h3>Description</h3>
    <p>
      Raw sensor data contains noise and values on different scales, which can obscure meaningful patterns and hinder model performance. Data cleansing normalizes the scale and removes noise, ensuring reliable and comparable data for deep learning.
    </p>
    <h3>Process Description</h3>
    <p>
      MinMaxScaler normalizes the photodiode signal to a [0, 1] range. A low-pass Butterworth filter removes high-frequency noise from both accelerometer and photodiode signals, isolating relevant changes for feature extraction. These steps produce clean, normalized signals for the CNN+LSTM models.
    </p>
    <pre><code>
from sklearn.preprocessing import MinMaxScaler
from scipy.signal import butter, filtfilt

scaler = MinMaxScaler()
pd_signal_scaled = scaler.fit_transform(pd_signal.values.reshape(-1, 1)).flatten()  # Scale photodiode

b, a = butter(N=2, Wn=2, fs=50, btype='low')  # Design low-pass filter
y_filtered = filtfilt(b, a, y_accel)           # Filter head movement
pd_signal_filtered = filtfilt(b, a, pd_signal_scaled)  # Filter photodiode
    </code></pre>
    <hr>
    <h2 id="features">3. Feature Extraction</h2>
    <h3>Description</h3>
    <p>
      Feature extraction transforms cleansed sensor data into variables for deep learning. For CNN+LSTM models, time-series windows (e.g., 30 seconds) are used as input sequences. Head nod and blink counts, or raw windowed signals, serve as indicators of drowsiness.
    </p>
    <h3>Process Description</h3>
    <p>
      Filtered signals are divided into 30-second windows. For classical ML, nods and blinks are counted by detecting downward threshold crossings. For CNN+LSTM, windowed sequences are reshaped for model input. This prepares the data for temporal pattern recognition.
    </p>
    <pre><code>
import numpy as np
window_size = 30 * 50  # 30 seconds * 50 Hz

# Reshape head movement data into windows for CNN+LSTM
head_windows = np.array([y_filtered[i:i+window_size] for i in range(0, len(y_filtered)-window_size, window_size)])

# Reshape photodiode data into windows for CNN+LSTM
blink_windows = np.array([pd_signal_filtered[i:i+window_size] for i in range(0, len(pd_signal_filtered)-window_size, window_size)])
    </code></pre>
    <hr>
    <h2 id="modeling">4. Deep Learning Modeling (CNN+LSTM)</h2>
    <h3>Description</h3>
    <p>
      Deep learning models combine convolutional layers (CNN) for spatial feature extraction and LSTM layers for temporal sequence learning. Each model receives windowed time-series data and outputs a drowsiness score (0.1–0.9). Separate models are built for head movement and blinking.
    </p>
    <h3>Process Description</h3>
    <p>
      The following code defines a simple CNN+LSTM model using TensorFlow/Keras. The model accepts windowed sensor data, applies convolutional filters, and learns temporal dependencies with LSTM. The output is a regression score for drowsiness prediction.
    </p>
    <pre><code>
import tensorflow as tf
from tensorflow.keras import layers, models

def build_cnn_lstm(input_shape):
    model = models.Sequential([
        layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),
        layers.MaxPooling1D(pool_size=2),
        layers.Conv1D(64, kernel_size=3, activation='relu'),
        layers.MaxPooling1D(pool_size=2),
        layers.LSTM(64, return_sequences=False),
        layers.Dense(1, activation='sigmoid')  # Output between 0 and 1
    ])
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

# Example usage:
# input_shape = (window_size, 1)
# head_model = build_cnn_lstm((window_size, 1))
# blink_model = build_cnn_lstm((window_size, 1))
    </code></pre>
    <hr>
    <h2 id="tuning">5. Model Tuning</h2>
    <h3>Description</h3>
    <p>
      Model tuning optimizes architecture and training parameters. Key parameters include window size, number of convolutional filters, LSTM units, learning rate, and regularization. Proper tuning improves accuracy and generalization.
    </p>
    <h3>Process Description</h3>
    <p>
      Hyperparameters are adjusted and models are retrained to find the best configuration. Validation metrics (e.g., MAE, loss) are monitored to avoid overfitting. Grid search or manual tuning can be used to select optimal values.
    </p>
    <pre><code>
# Example: Tune number of filters and LSTM units
model = models.Sequential([
    layers.Conv1D(64, kernel_size=5, activation='relu', input_shape=(window_size, 1)),  # More filters
    layers.MaxPooling1D(pool_size=2),
    layers.LSTM(128, return_sequences=False),  # More LSTM units
    layers.Dense(1, activation='sigmoid')
])
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')
    </code></pre>
    <hr>
    <h2 id="storage">6. Data Storage</h2>
    <h3>Description</h3>
    <p>
      Storing predictions with timestamps enables traceability and analysis. Both head movement and blink predictions are paired before saving. Data is stored in a CSV file for downstream processing.
    </p>
    <h3>Process Description</h3>
    <p>
      A buffer function waits for both predictions before writing to the CSV file. Each row contains a timestamp, head movement prediction, and blink prediction. This structure supports time-series analysis and integration with other systems.
    </p>
    <pre><code>
import csv
from datetime import datetime

def store_predictions(head_pred, blink_pred):
    timestamp = datetime.now().isoformat()
    with open('predictions.csv', 'a', newline='') as f:
        writer = csv.writer(f)
        writer.writerow([timestamp, head_pred, blink_pred])
    </code></pre>
    <hr>
    <h2 id="deployment">7. Deployment & Visualization</h2>
    <h3>Description</h3>
    <p>
      Deployment presents model outputs in a user-friendly format. Visualization supports interpretation and monitoring of drowsiness levels. Streamlit is used to build an interactive dashboard.
    </p>
    <h3>Process Description</h3>
    <p>
      The Streamlit app displays nod and blink predictions side by side. Users input values and view results instantly. This interface supports demonstration and monitoring.
    </p>
    <pre><code>
import streamlit as st

st.title("Drowsiness Detection Visualization")
nods = st.number_input("Nods per minute", min_value=0)
blinks = st.number_input("Blinks per minute", min_value=0)

if st.button("Show Prediction"):
    st.write(f"Nods: {nods} | Blinks: {blinks}")
    # Chart or category display can be added
    </code></pre>
    <hr>
    <h2 id="concerns">8. Areas of Concern and Research</h2>
    <ul class="list-disc list-inside mb-4 text-gray-700">
      <li><strong>Labeling for Data:</strong> Reliable ground truth labels are needed for supervised learning. Consider self-reports, expert annotation, or controlled experiments.</li>
      <li><strong>Threshold Selection:</strong> Thresholds for nod and blink detection should be tuned for each user and sensor setup.</li>
      <li><strong>Sampling Rate Consistency:</strong> Ensure all sensors use the same sampling rate, or resample data to align windows.</li>
      <li><strong>Model Evaluation:</strong> Use MAE, loss, and other metrics to assess model performance. Consider regression and classification evaluation for drowsiness scores.</li>
      <li><strong>Hyperparameter Optimization:</strong> Explore grid search, random search, or Bayesian optimization for tuning CNN+LSTM architectures.</li>
    </ul>
    <hr>
    <h2 id="glossary">Glossary</h2>
    <ul class="list-disc list-inside mb-4 text-gray-700">
      <li><strong>Accelerometer:</strong> Sensor measuring linear acceleration, used for head movement detection.</li>
      <li><strong>Photodiode:</strong> Sensor detecting changes in light intensity, used for blink detection.</li>
      <li><strong>Low-pass filter:</strong> Removes high-frequency noise from signals.</li>
      <li><strong>MinMaxScaler:</strong> Scales features to a consistent range.</li>
      <li><strong>Threshold crossing:</strong> Detects events by checking when a signal passes a set value.</li>
      <li><strong>Feature extraction:</strong> Deriving meaningful variables (e.g., nod count, blink count) from raw data.</li>
      <li><strong>CNN (Convolutional Neural Network):</strong> Deep learning architecture for spatial feature extraction.</li>
      <li><strong>LSTM (Long Short-Term Memory):</strong> Neural network layer for learning temporal dependencies in sequences.</li>
      <li><strong>Hyperparameter:</strong> Model configuration value set before training (e.g., learning rate, filter size).</li>
      <li><strong>MAE (Mean Absolute Error):</strong> Metric for regression model accuracy.</li>
      <li><strong>Streamlit:</strong> Python library for building interactive data apps.</li>
      <li><strong>CSV:</strong> File format for storing tabular data.</li>
    </ul>
  </section>
</div>
